{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3rVFtGLMJM",
        "colab_type": "text"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VS3FFSFLR3a",
        "colab_type": "text"
      },
      "source": [
        "Your assignment is to use the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from Kaggle to try and cluster types of cancer cells. \n",
        "\n",
        "It may be helpful to use PCA to reduce the dimensions of your data first in order to obtain --but then again, maybe not. I dunno, you're the data scientist, you tell me.ðŸ¤ª \n",
        "\n",
        "Here's the original dataset for your reference:\n",
        "\n",
        "<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899RK3bBn4OE",
        "colab_type": "text"
      },
      "source": [
        "## This is a supervised learning dataset\n",
        "\n",
        "(Because it has **labels** - The \"diagnosis\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws5R9X6hLJQ2",
        "colab_type": "code",
        "outputId": "fd1cb50b-9013-4e1f-d6a9-b0ef3828e496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA # You don't necessarily have to use this\n",
        "from sklearn.cluster import KMeans # You don't necessarily have to use this\n",
        "from sklearn.preprocessing import StandardScaler # You don't necessarily have to use this\n",
        "columns = ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
        "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
        "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
        "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
        "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
        "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
        "       'symmetry_worst', 'fractal_dimension_worst']\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Cancer_Cells.csv\",names=columns,skiprows=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDDqaU-ove4",
        "colab_type": "text"
      },
      "source": [
        "## Now it's an unsupervised learning dataset\n",
        "\n",
        "(Because we've removed the diagnosis label) - Use this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86MHoPJon_aC",
        "colab_type": "code",
        "outputId": "47e2b69e-5971-4527-ee1b-61044a52f425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "target = df['diagnosis']\n",
        "df = df.drop('diagnosis', axis=1)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302        17.99  ...          0.4601                  0.11890\n",
              "1    842517        20.57  ...          0.2750                  0.08902\n",
              "2  84300903        19.69  ...          0.3613                  0.08758\n",
              "3  84348301        11.42  ...          0.6638                  0.17300\n",
              "4  84358402        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0lAq-Rtdj7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "2b96bb04-1520-46cf-8005-0c6db0771fae"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  5.690000e+02   569.000000  ...      569.000000               569.000000\n",
              "mean   3.037183e+07    14.127292  ...        0.290076                 0.083946\n",
              "std    1.250206e+08     3.524049  ...        0.061867                 0.018061\n",
              "min    8.670000e+03     6.981000  ...        0.156500                 0.055040\n",
              "25%    8.692180e+05    11.700000  ...        0.250400                 0.071460\n",
              "50%    9.060240e+05    13.370000  ...        0.282200                 0.080040\n",
              "75%    8.813129e+06    15.780000  ...        0.317900                 0.092080\n",
              "max    9.113205e+08    28.110000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS7gHgW3fELn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As this is a breast cancer dataset, setting clusters to 2, either cancer present or not present.\n",
        "kmeans = KMeans(n_clusters=2,verbose=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THVx60Zkg_uG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "786e9cbe-fc6b-4a4c-a46d-cb65e39f7ff2"
      },
      "source": [
        "df.iloc[:,1:].head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYa1yhqegHgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "675f0f5c-1727-494b-8668-528946c91f0f"
      },
      "source": [
        "kmeans.fit(df.iloc[:,1:])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 78410137.14313614\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 2, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 118775165.1030783\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 87890905.98844929\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 2, inertia 80654451.95560884\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 3, inertia 78829115.27340402\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 4, inertia 78288357.07671174\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 5, inertia 78084899.21020217\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 6, inertia 77974622.18812649\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 7, inertia 77949789.73226756\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 8, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 9, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 104947850.86201715\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 83747960.19487129\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 2, inertia 79608977.50794916\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 3, inertia 78426946.05412115\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 4, inertia 78118051.46186261\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 5, inertia 77974622.18812649\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 6, inertia 77949789.73226756\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 7, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 8, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 79781865.1692148\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 78612318.62206028\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 2, inertia 78174426.75003316\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 3, inertia 78006757.62572165\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 4, inertia 77949789.73226756\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 5, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 6, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 79268105.37595238\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 78426946.05412115\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 2, inertia 78118051.46186261\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 3, inertia 77974622.18812649\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 4, inertia 77949789.73226756\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 5, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 6, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 82296047.91089612\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 78254212.8871352\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 2, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 3, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 103660307.04195975\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 82626898.05927433\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 2, inertia 78399579.34115468\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 3, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 4, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n",
            "Initialization complete\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 0, inertia 78546395.70849499\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 1, inertia 77988802.96453695\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 2, inertia 77943099.87829883\n",
            "start iteration\n",
            "done sorting\n",
            "end inner loop\n",
            "Iteration 3, inertia 77943099.87829883\n",
            "center shift 0.000000e+00 within tolerance 1.503675e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6S3jQAhge8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding the results and creating a dataframe\n",
        "kmeans_results = pd.DataFrame({'diagnosis':target,'kmeans_nopca':kmeans.labels_})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRNKS5SliVxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1041b55-440b-4d21-c4d5-a4588c7f4052"
      },
      "source": [
        "#the kmeans without pca idendified only 131 whereas it should have been closer to 200 as per the diagnosis data.\n",
        "kmeans_results.kmeans_nopca.sum()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFBDOF5TiCMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fa5eb4b4-933d-482b-8c5d-ec86d1932dc1"
      },
      "source": [
        "kmeans_results.diagnosis.value_counts()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4KJTOGxkhWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_of_squared_distances = []\n",
        "K = range(1,15)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km = km.fit(df.iloc[:,1:])\n",
        "    sum_of_squared_distances.append(km.inertia_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1FmdzNrkxmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "70161efb-618b-4948-8090-6df4e32812a8"
      },
      "source": [
        "sum_of_squared_distances"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[256677243.9542025,\n",
              " 77943099.87829883,\n",
              " 47336610.421990566,\n",
              " 29226541.651979793,\n",
              " 20612895.823981803,\n",
              " 16642406.184887392,\n",
              " 13249639.466602253,\n",
              " 11180785.409988163,\n",
              " 9515598.480111256,\n",
              " 8956008.77068112,\n",
              " 7487988.477305981,\n",
              " 6735169.8084669905,\n",
              " 6160333.26025084,\n",
              " 5714166.39098131]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud3kXTexk4ae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5541e33a-f458-46cc-e895-1a908abe1ded"
      },
      "source": [
        "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum_of_squared_distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()\n",
        "#This elbow at 2 indicates that taking clusters 2 for Kmeans was the correct decision"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZX4/wqc9jHxYv65AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH5iNk0SlnKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b628b80-3c29-4ea0-a9ed-cc3ff5031b45"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHKwPbD4lVqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "437aae44-85e0-44aa-fb11-c18cff8b5fe2"
      },
      "source": [
        "#Doing pca on the data without standarisation\n",
        "\n",
        "pca = PCA(n_components=30) #Same as the number of features\n",
        "pca.fit(df.iloc[:,1:])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=30, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1GekSPUl4ki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "887877dc-6f95-43d6-a5a0-ed3580e626bd"
      },
      "source": [
        "#As per the below variance the first 8 pca components cover the maximum variance, using the same for kmeans\n",
        "pca.explained_variance_\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.43782605e+05, 7.31010006e+03, 7.03833742e+02, 5.46487379e+01,\n",
              "       3.98900178e+01, 3.00458768e+00, 1.81533030e+00, 3.71466740e-01,\n",
              "       1.55513547e-01, 8.40612196e-02, 3.16089533e-02, 7.49736514e-03,\n",
              "       3.16165652e-03, 2.16150395e-03, 1.32653879e-03, 6.40269304e-04,\n",
              "       3.74883320e-04, 2.35169626e-04, 1.84583467e-04, 1.64180064e-04,\n",
              "       7.81102011e-05, 5.76111660e-05, 3.49172775e-05, 2.83952689e-05,\n",
              "       1.61463677e-05, 1.24902419e-05, 3.68048171e-06, 2.84790425e-06,\n",
              "       2.00491564e-06, 7.01997261e-07])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2RSVxeFm5fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d5f6cfa-a799-4186-e496-92bb115b4643"
      },
      "source": [
        "df_pca = pca.transform(df.iloc[:,1:])\n",
        "df_pca.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V80l5LMxnVzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24eab72c-a5f9-4195-81ee-eaa513eaeeab"
      },
      "source": [
        "df_pca[:,:8].shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvoZ3EcjnG7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d9c1cb1d-a3fe-4a0c-b4b9-f7eedbdd0420"
      },
      "source": [
        "pca_kmeans_nostd = KMeans(2)\n",
        "pca_kmeans_nostd.fit(df_pca[:,:8])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXr1ytMKnyiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_results['pca_nostd']=pca_kmeans_nostd.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGinWVZ_o4L7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f963bfd-30af-4894-df6b-0888fa3e2387"
      },
      "source": [
        "#Now standardising the data before implementing the pca\n",
        "scaler = StandardScaler()\n",
        "df_std = scaler.fit_transform(df.iloc[:,1:])\n",
        "df_std.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3CXNFZRpgaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e18d602-6ffe-4419-b195-6c26dc867405"
      },
      "source": [
        "#Now applying pca on the std data\n",
        "pca.fit(df_std)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=30, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnXCX7PqqAJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "71fc43c7-a0ad-44b3-ccf2-235b91f1a6e1"
      },
      "source": [
        "pca.explained_variance_"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.33049908e+01, 5.70137460e+00, 2.82291016e+00, 1.98412752e+00,\n",
              "       1.65163324e+00, 1.20948224e+00, 6.76408882e-01, 4.77456255e-01,\n",
              "       4.17628782e-01, 3.51310875e-01, 2.94433153e-01, 2.61621161e-01,\n",
              "       2.41782421e-01, 1.57286149e-01, 9.43006956e-02, 8.00034045e-02,\n",
              "       5.95036135e-02, 5.27114222e-02, 4.95647002e-02, 3.12142606e-02,\n",
              "       3.00256631e-02, 2.74877113e-02, 2.43836914e-02, 1.80867940e-02,\n",
              "       1.55085271e-02, 8.19203712e-03, 6.91261258e-03, 1.59213600e-03,\n",
              "       7.50121413e-04, 1.33279057e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iapva_rAq9bS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f4f6afc-b854-40a4-88af-aec79e9421af"
      },
      "source": [
        "df_std[:,:8].shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-3Mli3HpwmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Again taking the first 8 pca features as they contain the maximum variance\n",
        "df_pca_std = pca.transform(df_std)\n",
        "pca_kmeans_withstd = KMeans(2)\n",
        "pca_kmeans_withstd.fit(df_pca_std[:,:8])\n",
        "kmeans_results['pca_std']=pca_kmeans_withstd.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXGOSzUOrbpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_results['int_diagnosis'] = kmeans_results['diagnosis'].replace({'B':1,'M':0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rab8uu3BsS_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7e88e8cc-405c-4330-c0aa-7df5931e7424"
      },
      "source": [
        "kmeans_results.diagnosis.value_counts()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAheRv9PshvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f45b62c8-9d92-43c2-b9aa-2acd55fca6a1"
      },
      "source": [
        "kmeans_results.columns"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['diagnosis', 'kmeans_nopca', 'pca_nostd', 'pca_std', 'int_diagnosis'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYEKpQYLsfeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_columns = ['kmeans_nopca', 'pca_nostd', 'pca_std', 'int_diagnosis']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnSWwi6JtF15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c7c2a28a-6a28-4968-9b9f-d35ef051aa85"
      },
      "source": [
        "kmeans_results[result_columns].sum()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kmeans_nopca     131\n",
              "pca_nostd        438\n",
              "pca_std          380\n",
              "int_diagnosis    357\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "588xI_r8sOR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4d29dfb0-21e3-43fe-edf8-54dbc73b4256"
      },
      "source": [
        "kmeans_results[kmeans_results.diagnosis=='M'][result_columns].sum()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kmeans_nopca     130\n",
              "pca_nostd         82\n",
              "pca_std           37\n",
              "int_diagnosis      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8FOo7XtCGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ce1995ae-5939-448a-e6a6-3bbc39318ee7"
      },
      "source": [
        "kmeans_results[kmeans_results.diagnosis=='B'][result_columns].sum()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kmeans_nopca       1\n",
              "pca_nostd        356\n",
              "pca_std          343\n",
              "int_diagnosis    357\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rskC80k3OKMA",
        "colab_type": "text"
      },
      "source": [
        "# You take it from here!\n",
        "\n",
        "See what you can come up with. You have all the know-how! \n",
        "\n",
        "- You might want to do some data exploration to see if you can find specific columns that will help you find distinct clusters of cells\n",
        "- You might want to do PCA on this data to see if that helps you find distinct linearly-separable clusters.\n",
        "  - (In the real world, truly linearly-separable clusters are rare.)\n",
        "- You might want to use an elbow chart to decide on the number of clusters to use.\n",
        "- You might want to use a scree plot to decide how many principal components to include in your clustering.\n",
        "- You might want to standardize your data before PCA (If you decide to use PCA). \n",
        "\n",
        "## Manage your time and don't spend it all on data exploration or something like that. You got this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1AeAK8PNah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBwVaGOOYsq",
        "colab_type": "text"
      },
      "source": [
        "# Stretch Goal:\n",
        "\n",
        "Once you are satisfied with your clustering, go back and add back in the labels from the original dataset to check how accurate your clustering was. Remember that this will not be a possibility in true unsupervised learning, but it might be a helpful for your learning to be able to check your work against the \"ground truth\". Try different approaches and see which one is the most successful and try understand why that might be the case. If you go back and try different methods don't ever include the actual \"diagnosis\" labels in your clustering or PCA.\n",
        "\n",
        "**Side Note** Data Science is never DONE. You just reach a point where the cost isn't worth the benefit anymore. There's always more moderate to small improvements that we could make. Don't be a perfectionist, be a pragmatist."
      ]
    }
  ]
}