{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3rVFtGLMJM",
        "colab_type": "text"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VS3FFSFLR3a",
        "colab_type": "text"
      },
      "source": [
        "Your assignment is to use the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from Kaggle to try and cluster types of cancer cells. \n",
        "\n",
        "It may be helpful to use PCA to reduce the dimensions of your data first in order to obtain --but then again, maybe not. I dunno, you're the data scientist, you tell me.ðŸ¤ª \n",
        "\n",
        "Here's the original dataset for your reference:\n",
        "\n",
        "<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899RK3bBn4OE",
        "colab_type": "text"
      },
      "source": [
        "## This is a supervised learning dataset\n",
        "\n",
        "(Because it has **labels** - The \"diagnosis\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws5R9X6hLJQ2",
        "colab_type": "code",
        "outputId": "c3aeb13d-1091-47d6-c2a2-67221158b696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA # You don't necessarily have to use this\n",
        "from sklearn.cluster import KMeans # You don't necessarily have to use this\n",
        "from sklearn.preprocessing import StandardScaler # You don't necessarily have to use this\n",
        "columns = ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
        "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
        "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
        "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
        "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
        "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
        "       'symmetry_worst', 'fractal_dimension_worst']\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Cancer_Cells.csv\",names=columns,skiprows=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDDqaU-ove4",
        "colab_type": "text"
      },
      "source": [
        "## Now it's an unsupervised learning dataset\n",
        "\n",
        "(Because we've removed the diagnosis label) - Use this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86MHoPJon_aC",
        "colab_type": "code",
        "outputId": "09a6995c-c88e-400a-d73a-59acedd4e36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "target = df['diagnosis']\n",
        "df = df.drop(['diagnosis','id'], axis=1)#removing id as it is not required for clustering\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0lAq-Rtdj7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "1c3ced4b-c1a2-4a1f-d98a-53b8c947d31e"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "count   569.000000    569.000000  ...      569.000000               569.000000\n",
              "mean     14.127292     19.289649  ...        0.290076                 0.083946\n",
              "std       3.524049      4.301036  ...        0.061867                 0.018061\n",
              "min       6.981000      9.710000  ...        0.156500                 0.055040\n",
              "25%      11.700000     16.170000  ...        0.250400                 0.071460\n",
              "50%      13.370000     18.840000  ...        0.282200                 0.080040\n",
              "75%      15.780000     21.800000  ...        0.317900                 0.092080\n",
              "max      28.110000     39.280000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud3kXTexk4ae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1202437c-5275-4516-e91c-ef92de0debe3"
      },
      "source": [
        "#Plotting elbow graph to decide on number of clusters\n",
        "sum_of_squared_distances = []\n",
        "K = range(1,15)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km = km.fit(df.iloc[:,1:])\n",
        "    sum_of_squared_distances.append(km.inertia_)\n",
        "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum_of_squared_distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()\n",
        "#This elbow at 2 indicates that taking clusters 2 for Kmeans was the correct decision"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKyd/wO47WmOoS0TxAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS7gHgW3fELn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As this is a breast cancer dataset, setting clusters to 2, either cancer present or not present.\n",
        "kmeans = KMeans(n_clusters=2,random_state=42) #adding random state for reproducability\n",
        "#Now doing pca on data without standardisation and again pca after standardisation\n",
        "pca = PCA(n_components=30) #Same as the number of features\n",
        "#Now standardising the data before implementing the pca\n",
        "scaler = StandardScaler()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD0jSXUw24CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#running standardisation on data\n",
        "df_std = scaler.fit_transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--CO7_oI6o4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "604a0298-5c5b-464c-e7e0-2102a88f69f3"
      },
      "source": [
        "#running pca on regular data\n",
        "pca_df = pca.fit_transform(df)\n",
        "print(pca.explained_variance_ratio_)\n",
        "np.cumsum(pca.explained_variance_ratio_)\n",
        "#First three pca components account for maximum variance"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9.82044672e-01 1.61764899e-02 1.55751075e-03 1.20931964e-04\n",
            " 8.82724536e-05 6.64883951e-06 4.01713682e-06 8.22017197e-07\n",
            " 3.44135279e-07 1.86018721e-07 6.99473205e-08 1.65908880e-08\n",
            " 6.99641650e-09 4.78318306e-09 2.93549214e-09 1.41684927e-09\n",
            " 8.29577731e-10 5.20405883e-10 4.08463983e-10 3.63313378e-10\n",
            " 1.72849737e-10 1.27487508e-10 7.72682973e-11 6.28357718e-11\n",
            " 3.57302295e-11 2.76396041e-11 8.14452259e-12 6.30211541e-12\n",
            " 4.43666945e-12 1.55344680e-12]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.98204467, 0.99822116, 0.99977867, 0.9998996 , 0.99998788,\n",
              "       0.99999453, 0.99999854, 0.99999936, 0.99999971, 0.99999989,\n",
              "       0.99999996, 0.99999998, 0.99999999, 0.99999999, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiNas9m0_zcK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b8286eee-2d9d-4826-ef58-946a227ee129"
      },
      "source": [
        "#running pca on standardised data\n",
        "pca_df_std = pca.fit_transform(df_std)\n",
        "print(pca.explained_variance_ratio_)\n",
        "np.cumsum(pca.explained_variance_ratio_)\n",
        "#First 10 pca components account for maximum variance"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.42720256e-01 1.89711820e-01 9.39316326e-02 6.60213492e-02\n",
            " 5.49576849e-02 4.02452204e-02 2.25073371e-02 1.58872380e-02\n",
            " 1.38964937e-02 1.16897819e-02 9.79718988e-03 8.70537901e-03\n",
            " 8.04524987e-03 5.23365745e-03 3.13783217e-03 2.66209337e-03\n",
            " 1.97996793e-03 1.75395945e-03 1.64925306e-03 1.03864675e-03\n",
            " 9.99096464e-04 9.14646751e-04 8.11361259e-04 6.01833567e-04\n",
            " 5.16042379e-04 2.72587995e-04 2.30015463e-04 5.29779290e-05\n",
            " 2.49601032e-05 4.43482743e-06]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.44272026, 0.63243208, 0.72636371, 0.79238506, 0.84734274,\n",
              "       0.88758796, 0.9100953 , 0.92598254, 0.93987903, 0.95156881,\n",
              "       0.961366  , 0.97007138, 0.97811663, 0.98335029, 0.98648812,\n",
              "       0.98915022, 0.99113018, 0.99288414, 0.9945334 , 0.99557204,\n",
              "       0.99657114, 0.99748579, 0.99829715, 0.99889898, 0.99941502,\n",
              "       0.99968761, 0.99991763, 0.99997061, 0.99999557, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CsMbLXQD3xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c61e28f9-8bbe-4d9c-f467-27ae6f7d67ec"
      },
      "source": [
        "pca_df[:,:3].shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfaI2O6wBsy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now running kmeans on pca transformation data as per maximum contained variance\n",
        "kmeans_nopca = kmeans.fit_predict(df) #without pca implemented on data\n",
        "pca_kmeans_nostd = kmeans.fit_predict(pca_df[:,:3]) #top 3 pca components cover the maximum variance\n",
        "pca_kmeans_std = kmeans.fit_predict(pca_df_std[:,:3]) #top 10 pca components cover the maximum variance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1cDodIkEamt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding the results and creating a dataframe\n",
        "kmeans_results = pd.DataFrame({'diagnosis':target,'kmeans_nopca':kmeans_nopca,'pca_kmeans_nostd':pca_kmeans_nostd,'pca_kmeans_std':pca_kmeans_std})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6S3jQAhge8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7fa0e2d3-ab6b-4fe6-8e34-38f4b9a93edf"
      },
      "source": [
        "kmeans_results.head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>kmeans_nopca</th>\n",
              "      <th>pca_kmeans_nostd</th>\n",
              "      <th>pca_kmeans_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  diagnosis  kmeans_nopca  pca_kmeans_nostd  pca_kmeans_std\n",
              "0         M             0                 0               1\n",
              "1         M             0                 0               1\n",
              "2         M             0                 0               1\n",
              "3         M             1                 1               1\n",
              "4         M             0                 0               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFBDOF5TiCMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3959ca9e-f768-4267-a5ba-8ff18b80d9b6"
      },
      "source": [
        "kmeans_results.diagnosis.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXGOSzUOrbpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_results['int_diagnosis'] = kmeans_results['diagnosis'].replace({'B':1,'M':0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rab8uu3BsS_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4aa03f4d-39e8-4490-f453-30d6cf03ad61"
      },
      "source": [
        "kmeans_results.diagnosis.value_counts()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYEKpQYLsfeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_columns = ['kmeans_nopca', 'pca_kmeans_nostd', 'pca_kmeans_std', 'int_diagnosis']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnSWwi6JtF15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "028e1e78-4f0d-49d4-ab86-c34545cdebe8"
      },
      "source": [
        "kmeans_results[result_columns].sum()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kmeans_nopca        438\n",
              "pca_kmeans_nostd    438\n",
              "pca_kmeans_std      189\n",
              "int_diagnosis       357\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "588xI_r8sOR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "89468d6a-a9af-4b29-af40-36e0fe67a7ce"
      },
      "source": [
        "kmeans_results[kmeans_results.diagnosis=='M'][result_columns].sum()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kmeans_nopca         82\n",
              "pca_kmeans_nostd     82\n",
              "pca_kmeans_std      175\n",
              "int_diagnosis         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8FOo7XtCGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "69832df5-0717-4513-a557-b7c732e8b0d8"
      },
      "source": [
        "kmeans_results[kmeans_results.diagnosis=='B'][result_columns].sum()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kmeans_nopca        356\n",
              "pca_kmeans_nostd    356\n",
              "pca_kmeans_std       14\n",
              "int_diagnosis       357\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rskC80k3OKMA",
        "colab_type": "text"
      },
      "source": [
        "# You take it from here!\n",
        "\n",
        "See what you can come up with. You have all the know-how! \n",
        "\n",
        "- You might want to do some data exploration to see if you can find specific columns that will help you find distinct clusters of cells\n",
        "- You might want to do PCA on this data to see if that helps you find distinct linearly-separable clusters.\n",
        "  - (In the real world, truly linearly-separable clusters are rare.)\n",
        "- You might want to use an elbow chart to decide on the number of clusters to use.\n",
        "- You might want to use a scree plot to decide how many principal components to include in your clustering.\n",
        "- You might want to standardize your data before PCA (If you decide to use PCA). \n",
        "\n",
        "## Manage your time and don't spend it all on data exploration or something like that. You got this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1AeAK8PNah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBwVaGOOYsq",
        "colab_type": "text"
      },
      "source": [
        "# Stretch Goal:\n",
        "\n",
        "Once you are satisfied with your clustering, go back and add back in the labels from the original dataset to check how accurate your clustering was. Remember that this will not be a possibility in true unsupervised learning, but it might be a helpful for your learning to be able to check your work against the \"ground truth\". Try different approaches and see which one is the most successful and try understand why that might be the case. If you go back and try different methods don't ever include the actual \"diagnosis\" labels in your clustering or PCA.\n",
        "\n",
        "**Side Note** Data Science is never DONE. You just reach a point where the cost isn't worth the benefit anymore. There's always more moderate to small improvements that we could make. Don't be a perfectionist, be a pragmatist."
      ]
    }
  ]
}