{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3rVFtGLMJM",
        "colab_type": "text"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VS3FFSFLR3a",
        "colab_type": "text"
      },
      "source": [
        "Your assignment is to use the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from Kaggle to try and cluster types of cancer cells. \n",
        "\n",
        "It may be helpful to use PCA to reduce the dimensions of your data first in order to obtain --but then again, maybe not. I dunno, you're the data scientist, you tell me.ðŸ¤ª \n",
        "\n",
        "Here's the original dataset for your reference:\n",
        "\n",
        "<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899RK3bBn4OE",
        "colab_type": "text"
      },
      "source": [
        "## This is a supervised learning dataset\n",
        "\n",
        "(Because it has **labels** - The \"diagnosis\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws5R9X6hLJQ2",
        "colab_type": "code",
        "outputId": "34a209e5-f159-4c10-a166-f20cce3ec69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA # You don't necessarily have to use this\n",
        "from sklearn.cluster import KMeans # You don't necessarily have to use this\n",
        "from sklearn.preprocessing import StandardScaler # You don't necessarily have to use this\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Cancer_Cells.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 33)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDDqaU-ove4",
        "colab_type": "text"
      },
      "source": [
        "## Now it's an unsupervised learning dataset\n",
        "\n",
        "(Because we've removed the diagnosis label) - Use this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86MHoPJon_aC",
        "colab_type": "code",
        "outputId": "66a22dee-1aca-4022-bde8-6eac522247f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df = df.drop('diagnosis', axis=1)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302        17.99  ...                  0.11890          NaN\n",
              "1    842517        20.57  ...                  0.08902          NaN\n",
              "2  84300903        19.69  ...                  0.08758          NaN\n",
              "3  84348301        11.42  ...                  0.17300          NaN\n",
              "4  84358402        20.29  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rskC80k3OKMA",
        "colab_type": "text"
      },
      "source": [
        "# You take it from here!\n",
        "\n",
        "See what you can come up with. You have all the know-how! \n",
        "\n",
        "- You might want to do some data exploration to see if you can find specific columns that will help you find distinct clusters of cells\n",
        "- You might want to do PCA on this data to see if that helps you find distinct linearly-separable clusters.\n",
        "  - (In the real world, truly linearly-separable clusters are rare.)\n",
        "- You might want to use an elbow chart to decide on the number of clusters to use.\n",
        "- You might want to use a scree plot to decide how many principal components to include in your clustering.\n",
        "- You might want to standardize your data before PCA (If you decide to use PCA). \n",
        "\n",
        "## Manage your time and don't spend it all on data exploration or something like that. You got this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Jx1kn8E_3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "a50257c1-6bd2-463d-cd06-8f115552d687"
      },
      "source": [
        "print(df.shape)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                           0\n",
              "radius_mean                  0\n",
              "texture_mean                 0\n",
              "perimeter_mean               0\n",
              "area_mean                    0\n",
              "smoothness_mean              0\n",
              "compactness_mean             0\n",
              "concavity_mean               0\n",
              "concave points_mean          0\n",
              "symmetry_mean                0\n",
              "fractal_dimension_mean       0\n",
              "radius_se                    0\n",
              "texture_se                   0\n",
              "perimeter_se                 0\n",
              "area_se                      0\n",
              "smoothness_se                0\n",
              "compactness_se               0\n",
              "concavity_se                 0\n",
              "concave points_se            0\n",
              "symmetry_se                  0\n",
              "fractal_dimension_se         0\n",
              "radius_worst                 0\n",
              "texture_worst                0\n",
              "perimeter_worst              0\n",
              "area_worst                   0\n",
              "smoothness_worst             0\n",
              "compactness_worst            0\n",
              "concavity_worst              0\n",
              "concave points_worst         0\n",
              "symmetry_worst               0\n",
              "fractal_dimension_worst      0\n",
              "Unnamed: 32                569\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjCwP99SFc04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['Unnamed: 32'],axis=1)\n",
        "df1 = df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1AeAK8PNah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_of_squared_distances = []\n",
        "K = range(1,15)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km = km.fit(df)\n",
        "    sum_of_squared_distances.append(km.inertia_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gbcnD9gEC4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1aef0fe8-8215-4635-93ae-d98af87342cd"
      },
      "source": [
        "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum_of_squared_distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL-qS9d5HO0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "56cfbd31-c997-40e3-d37b-64b0f99d6b95"
      },
      "source": [
        "# kmeans = KMeans(n_clusters=3)\n",
        "# kmeans.fit(df)\n",
        "# labels = kmeans.labels_\n",
        "# new_series = pd.Series(labels)\n",
        "# df['clusters'] = new_series.values\n",
        "kmean = KMeans(n_clusters=2)\n",
        "kmean.fit(df)\n",
        "labels = kmean.labels_\n",
        "label_series = pd.Series(labels)\n",
        "df['clusters'] = label_series.values\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>clusters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  ...  fractal_dimension_worst  clusters\n",
              "0    842302        17.99  ...                  0.11890         0\n",
              "1    842517        20.57  ...                  0.08902         0\n",
              "2  84300903        19.69  ...                  0.08758         0\n",
              "3  84348301        11.42  ...                  0.17300         0\n",
              "4  84358402        20.29  ...                  0.07678         0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORWnZo-gHO4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "2799e7ff-94c8-4486-9faa-261f9f12d191"
      },
      "source": [
        "df.hist(['clusters'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fe011fe0898>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6TGGfSS1Lj/B4EZr+YuhX4tAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2w3WBRFID0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBwVaGOOYsq",
        "colab_type": "text"
      },
      "source": [
        "# Stretch Goal:\n",
        "\n",
        "Once you are satisfied with your clustering, go back and add back in the labels from the original dataset to check how accurate your clustering was. Remember that this will not be a possibility in true unsupervised learning, but it might be a helpful for your learning to be able to check your work against the \"ground truth\". Try different approaches and see which one is the most successful and try understand why that might be the case. If you go back and try different methods don't ever include the actual \"diagnosis\" labels in your clustering or PCA.\n",
        "\n",
        "**Side Note** Data Science is never DONE. You just reach a point where the cost isn't worth the benefit anymore. There's always more moderate to small improvements that we could make. Don't be a perfectionist, be a pragmatist."
      ]
    }
  ]
}