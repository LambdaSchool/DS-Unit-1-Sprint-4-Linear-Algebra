{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tclack88/DS-Unit-1-Sprint-4-Linear-Algebra/blob/master/module4-clustering/Cell_Clustering_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3rVFtGLMJM",
        "colab_type": "text"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VS3FFSFLR3a",
        "colab_type": "text"
      },
      "source": [
        "# 1) Use the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from Kaggle to try and cluster types of cancer cells. \n",
        "\n",
        "Here's the original dataset for your reference:\n",
        "\n",
        "<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899RK3bBn4OE",
        "colab_type": "text"
      },
      "source": [
        "## This is a supervised learning dataset\n",
        "\n",
        "(Because it has **labels** - The \"diagnosis\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws5R9X6hLJQ2",
        "colab_type": "code",
        "outputId": "7a01bb5e-2f7a-4b2f-ece6-dec225c2af8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA # You don't necessarily have to use this\n",
        "from sklearn.cluster import KMeans # You don't necessarily have to use this\n",
        "from sklearn.preprocessing import StandardScaler # You don't necessarily have to use this\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Cancer_Cells.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 33)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDDqaU-ove4",
        "colab_type": "text"
      },
      "source": [
        "## Now it's an unsupervised learning dataset\n",
        "\n",
        "(Because we've removed the diagnosis label) - Use this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86MHoPJon_aC",
        "colab_type": "code",
        "outputId": "3df91acd-ccf7-47fd-9f05-533cadd93905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "df_original = df.copy()\n",
        "df = df.drop('diagnosis', axis=1)\n",
        "df.head()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302        17.99  ...                  0.11890          NaN\n",
              "1    842517        20.57  ...                  0.08902          NaN\n",
              "2  84300903        19.69  ...                  0.08758          NaN\n",
              "3  84348301        11.42  ...                  0.17300          NaN\n",
              "4  84358402        20.29  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rskC80k3OKMA",
        "colab_type": "text"
      },
      "source": [
        "## Let's do it!\n",
        "\n",
        "- You might want to do some data exploration to see if you can find specific columns that will help you find distinct clusters of cells\n",
        "- You might want to use the elbow method to decide on the number of clusters to use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8xzhtHupvb9",
        "colab_type": "text"
      },
      "source": [
        "### By hand - 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMGasNF9rXaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(columns=['Unnamed: 32']) # This appears to be a useless array of nans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyTNeK3JyFCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "2d67e1d3-2f27-4c5f-a3d6-9b80db5455f8"
      },
      "source": [
        "# Using a k-means library first to choose the best number of clusters\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "distortions = []\n",
        "K = range(1,10)\n",
        "for k in K:\n",
        "  kmean_model = KMeans(n_clusters=k).fit(df)\n",
        "  kmean_model.fit(df)\n",
        "  distortions.append(sum(np.min(cdist(df,kmean_model.cluster_centers_,'euclidean'),axis=1))/df.shape[0])\n",
        "  \n",
        "plt.plot(K,distortions)\n",
        "plt.xlabel('choice of k')\n",
        "plt.ylabel('Distance from cluster centers');"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAERCAYAAAB4jRxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNzOrEi74ZmZVwgXfzKxK/H9j0E3HIYYK1gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO_Tn_lKIcs4",
        "colab_type": "text"
      },
      "source": [
        "From the above elbow plot, 3 clusters centers is ideal, but then later I looked at the dataset and realized there's only two things being predicted inthe diagnosis, M, and B (malignant and benign) so we only need two clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUqMqCHRgj0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "728eafa0-8966-4dff-84b1-dcc88cea72c0"
      },
      "source": [
        "n_clusters = 2\n",
        "centroids = df.sample(n_clusters)\n",
        "\n",
        "\n",
        "\n",
        "def get_centroids(df, column_header):\n",
        "  headers = []\n",
        "  values = []\n",
        "  for col in list(df.columns):\n",
        "    header = col\n",
        "    headers.append(header)\n",
        "    value = [df[col][df[column_header] == i].mean() for i in range(n_clusters)]\n",
        "    values.append(value)\n",
        "    data = dict(zip(headers,values))\n",
        "  return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_nearest_centroid(df, centroids):\n",
        "  last_centroids = [np.random.choice(list(range(n_clusters)))] * df.shape[0]\n",
        "  df_temp = df.copy()\n",
        "  i = 0\n",
        "  \n",
        "  while True:\n",
        "    if i > 0:\n",
        "      centroids = get_centroids(df_temp, 'cluster' + str(i-1))\n",
        "    \n",
        "    col_names = list(df.columns)\n",
        "    distances = cdist(df_temp[col_names], centroids[col_names])\n",
        "    nearest_centroids = np.argmin(distances, axis=1)\n",
        "    \n",
        "    df_temp['cluster' + str(i)] = nearest_centroids\n",
        "    \n",
        "    if (list(nearest_centroids) == list(last_centroids)):\n",
        "      return df_temp\n",
        "    else:\n",
        "      i +=1\n",
        "      last_centroids = nearest_centroids\n",
        "      \n",
        "      \n",
        "      \n",
        "  \n",
        "  \n",
        "hand_kmeans = find_nearest_centroid(df, centroids)\n",
        "hand_kmeans.head(10)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>cluster0</th>\n",
              "      <th>cluster1</th>\n",
              "      <th>cluster2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>843786</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.03345</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.01137</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>844359</td>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>3.180</td>\n",
              "      <td>53.91</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.01382</td>\n",
              "      <td>0.02254</td>\n",
              "      <td>0.01039</td>\n",
              "      <td>0.01369</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.1932</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>84458202</td>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>1.3770</td>\n",
              "      <td>3.856</td>\n",
              "      <td>50.96</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.03029</td>\n",
              "      <td>0.02488</td>\n",
              "      <td>0.01448</td>\n",
              "      <td>0.01486</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.1556</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>844981</td>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>1.0020</td>\n",
              "      <td>2.406</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0.005731</td>\n",
              "      <td>0.03502</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>0.01226</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>84501001</td>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.94</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.07217</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.01432</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  texture_mean  ...  cluster0  cluster1  cluster2\n",
              "0    842302        17.99         10.38  ...         1         1         1\n",
              "1    842517        20.57         17.77  ...         1         1         1\n",
              "2  84300903        19.69         21.25  ...         0         1         1\n",
              "3  84348301        11.42         20.38  ...         0         1         1\n",
              "4  84358402        20.29         14.34  ...         0         1         1\n",
              "5    843786        12.45         15.70  ...         1         1         1\n",
              "6    844359        18.25         19.98  ...         1         1         1\n",
              "7  84458202        13.71         20.83  ...         0         1         1\n",
              "8    844981        13.00         21.82  ...         1         1         1\n",
              "9  84501001        12.46         24.04  ...         0         1         1\n",
              "\n",
              "[10 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S-mkPgsplHg",
        "colab_type": "text"
      },
      "source": [
        "### By hand - 2\n",
        "Ignore for now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iDdibIGKmYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### IGNORE THIS - SIDE WORK ########\n",
        "\n",
        "# df_sample = df.iloc[:,1:3]\n",
        "# df_sample.plot.scatter('radius_mean','texture_mean')\n",
        "# centroids= df_sample.sample(2)\n",
        "\n",
        "# print(centroids)\n",
        "# print(df_sample.head())\n",
        "\n",
        "# def find_centroids(df, new_groups):\n",
        "#   centroids = []\n",
        "#  # for col in df:\n",
        "\n",
        "    \n",
        "# def check_for_convergence(df):\n",
        "#    if (df.iloc[:,-1].equals(df.iloc[:,-2])) or (df.iloc[:,-1].equals(df.iloc[:,-3])):\n",
        "#       return True\n",
        "#    else:\n",
        "#     return False\n",
        "    \n",
        "    \n",
        "# def add_cluster_iteration(df_sample,i):\n",
        "#   global centroids\n",
        "#   distances = cdist(df_sample,centroids,'euclidean')\n",
        "#   new_groups = pd.Series(np.argmin(distances,axis=1))\n",
        "#   df_sample['cluster_'+str(i)] = new_groups\n",
        "#   centroids = find_centroids(df_sample,new_groups)\n",
        "#   return df_sample\n",
        "\n",
        "  \n",
        "# # new_df_sample = add_cluster_iteration(df_sample,1)\n",
        "# # new_df_sample\n",
        "\n",
        "# def run_kmeans(df):\n",
        "#   converged = check_for_convergence(df)\n",
        "#   i = 1\n",
        "#   while not converged:\n",
        "#     df = add_cluster_iteration(df,i)\n",
        "#     i += 1\n",
        "#     converged = check_for_convergence(df)\n",
        "#   return df\n",
        "\n",
        "# run_kmeans(df_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b6RXZF_pzEt",
        "colab_type": "text"
      },
      "source": [
        "### With libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLMcbKjsp1sA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters = 2)\n",
        "kmeans.fit(df)\n",
        "\n",
        "library_labels = kmeans.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTWyrFiNpMOn",
        "colab_type": "text"
      },
      "source": [
        "## Check you work: \n",
        "\n",
        "This is something that in a truly unsupervised learning situation **WOULD NOT BE POSSIBLE**. But for educational purposes go back and grab the true dianosis column (label) from the original dataset. Take your cluster labels and compare them to the original diagnosis column. You can make scatterplots for each to see how they compare or you can calculate a percent accuracy score like: \n",
        "\\begin{align}\n",
        "\\frac{\\text{Num Correct Labels}}{\\text{Num Total Observations}}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDfMEnK1pPCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_labels(letter):\n",
        "  if letter == 'M':\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "actual_labels = df_original.diagnosis.apply(convert_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLUr4IxFs82F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hand_labels = hand_kmeans.iloc[:,-1]\n",
        "hand_labels = (hand_labels + 1) % 1   # it is opposite, so must switch label data\n",
        "\n",
        "hand_labels = np.array(hand_labels)\n",
        "actual_labels = np.array(actual_labels)  #convert pd series to nparray\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQjQxW19spyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "69c471fb-7ec9-4039-c290-698a35d82358"
      },
      "source": [
        "print('actual labels :',actual_labels[0:25])\n",
        "print('hand labels:   ',hand_labels[0:25])\n",
        "print('library labels:',library_labels[0:25])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual labels : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
            "hand labels:    [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "library labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee8fYfMft-OS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "23d595d3-1e50-40ba-a4eb-95d5c5985a42"
      },
      "source": [
        "compare = pd.DataFrame({'actual':actual_labels,'hand':hand_labels,'library':library_labels})\n",
        "print('Actual vs hand:\\n',compare.actual.eq(compare.hand).sum()/compare.shape[0])\n",
        "print('\\nlibrary vs hand:\\n',compare.actual.eq(compare.library).sum()/compare.shape[0])"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual vs hand:\n",
            " 0.37258347978910367\n",
            "\n",
            "library vs hand:\n",
            " 0.37434094903339193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BedOTS0eJ9_K",
        "colab_type": "text"
      },
      "source": [
        "# 2) Perform PCA on your dataset first and *then* use k-means clustering. \n",
        "\n",
        "- You need to standardize your data before PCA.\n",
        "- First try clustering just on PC1 and PC2 so that you can make a scatterplot of your clustering.\n",
        "- Then use use a scree plot to decide how many principal components to include in your clustering, and use however many principal components you need in order to retain 90% of the variation of the original dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1AeAK8PNah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(10)\n",
        "pca.fit(df)\n",
        "\n",
        "data = pca.transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQMsbD7AyiOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans(n_clusters = 2)\n",
        "kmeans.fit(data)\n",
        "\n",
        "pca_lib_labels = kmeans.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soiwnGulzC65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "329e6c45-1549-46b3-f6e3-73aac05977db"
      },
      "source": [
        "actual_pca_compare = pd.DataFrame({'actual':actual_labels,'pca':pca_lib_labels})\n",
        "actual_pca_compare.actual.eq(actual_pca_compare.pca).sum()/actual_pca_compare.shape[0]"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37434094903339193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI4Siw1ppN0M",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrfbzfBROpP",
        "colab_type": "text"
      },
      "source": [
        "## Check your work: \n",
        "\n",
        "- Compare your PC1, PC2 clustering scatterplot to the clustering scatterplots you made on the raw data\n",
        "- Calculate accuracy scores for both the PC1,PC2 Principal component clustering and the 90% of explained variance clustering.\n",
        "\n",
        "How do your accuracy scores when preprocessing the data with PCA compare to the accuracy when clustering on the raw data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSdTTLNiz3vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec2971c8-a764-4d52-bb28-de96e93d63fc"
      },
      "source": [
        "actual_pca_compare = pd.DataFrame({'actual':actual_labels,'pca':pca_lib_labels})\n",
        "actual_pca_compare.actual.eq(actual_pca_compare.pca).sum()/actual_pca_compare.shape[0]"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37434094903339193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBwVaGOOYsq",
        "colab_type": "text"
      },
      "source": [
        "# Stretch Goals:\n",
        "\n",
        "- Study for the Sprint Challenge\n",
        "- Work on your Data Storytelling Project\n",
        "- Practice your two-minute presentation for your Data Storytelling Project"
      ]
    }
  ]
}