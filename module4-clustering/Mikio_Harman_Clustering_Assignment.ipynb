{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mikio Harman Clustering Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpHarm88/DS-Unit-1-Sprint-4-Linear-Algebra/blob/master/module4-clustering/Mikio_Harman_Clustering_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3rVFtGLMJM",
        "colab_type": "text"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VS3FFSFLR3a",
        "colab_type": "text"
      },
      "source": [
        "# 1) Use the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from Kaggle to try and cluster types of cancer cells. \n",
        "\n",
        "Here's the original dataset for your reference:\n",
        "\n",
        "<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899RK3bBn4OE",
        "colab_type": "text"
      },
      "source": [
        "## This is a supervised learning dataset\n",
        "\n",
        "(Because it has **labels** - The \"diagnosis\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws5R9X6hLJQ2",
        "colab_type": "code",
        "outputId": "c1adafbe-7edc-4b71-c65d-c72a0d9e9bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA # You don't necessarily have to use this\n",
        "from sklearn.cluster import KMeans # You don't necessarily have to use this\n",
        "from sklearn.preprocessing import StandardScaler # You don't necessarily have to use this\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Cancer_Cells.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 33)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDDqaU-ove4",
        "colab_type": "text"
      },
      "source": [
        "## Now it's an unsupervised learning dataset\n",
        "\n",
        "(Because we've removed the diagnosis label) - Use this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86MHoPJon_aC",
        "colab_type": "code",
        "outputId": "fd0e2b7f-845c-46eb-ce07-2be6d27b3992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df = df.drop(['diagnosis', 'id', 'Unnamed: 32'], axis=1)\n",
        "df.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rskC80k3OKMA",
        "colab_type": "text"
      },
      "source": [
        "## Let's do it!\n",
        "\n",
        "- You might want to do some data exploration to see if you can find specific columns that will help you find distinct clusters of cells\n",
        "- You might want to use the elbow method to decide on the number of clusters to use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U92Y3jNKPpjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "6f5e48dc-bceb-427d-dbc4-f93c044279bf"
      },
      "source": [
        "# Perform K-Means Clustering on the Dataset\n",
        "df1 = df[['radius_mean', 'texture_mean']]\n",
        "\n",
        "\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "# X = df.values stores in numpy array\n",
        "kmeans.fit(df)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "print(labels)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0\n",
            " 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aO-fU5zi5xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJKCxUDvSZoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "ab33646b-78c3-49e8-cf11-c84b7a167909"
      },
      "source": [
        "df['cluster'] = kmeans.labels_\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "colors = {0:'red', 1:'blue'}\n",
        "grouped = df.groupby('cluster')\n",
        "\n",
        "for key, group in grouped:\n",
        "      group.plot(ax=ax, kind='scatter', x='radius_mean', y='texture_mean', label=key, color=colors[key])\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAELCAYAAADURYGZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQSg5oggEQRBKjigCQRCEkvP/AWiJWQuiNjVPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3NaORi2ehoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_centroids(df, column_header):\n",
        "  x = [df.x[df[column_header]==0].mean(), df.x[df[column_header]==1].mean(), df.x[df[column_header]==2].mean()]\n",
        "  y = [df.y[df[column_header]==0].mean(), df.y[df[column_header]==1].mean(), df.y[df[column_header]==2].mean()]\n",
        "  data = {'x': x, 'y' : y}\n",
        "  return pd.DataFrame(data)\n",
        "\n",
        "def plot_clusters(df, column_header, centroids):\n",
        "  colors = {0:'red', 1:'green', 2:'yellow'}\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(centroids.iloc[0].x, centroids.iloc[0].y, \"ok\")\n",
        "  ax.plot(centroids.iloc[1].x, centroids.iloc[1].y, \"ok\")\n",
        "  ax.plot(centroids.iloc[2].x, centroids.iloc[2].y, \"ok\")\n",
        "  grouped = df.groupby(column_header)\n",
        "  for key, group in grouped:\n",
        "      group.plot(ax=ax, kind='scatter', x='radius_mean', y='texture_mean', label=key, color=colors[key])\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "  centroids = get_centroids(df1, 'clusters')\n",
        "  plot_clusters(df1, 'clusters', centroids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ghqYSxrP_FE",
        "colab_type": "text"
      },
      "source": [
        "## Check you work: \n",
        "\n",
        "This is something that in a truly unsupervised learning situation **WOULD NOT BE POSSIBLE**. But for educational purposes go back and grab the true dianosis column (label) from the original dataset. Take your cluster labels and compare them to the original diagnosis column. You can make scatterplots for each to see how they compare or you can calculate a percent accuracy score like: \n",
        "\\begin{align}\n",
        "\\frac{\\text{Num Correct Labels}}{\\text{Num Total Observations}}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIG7-yGLP-eA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "3d0f8030-34ea-4431-8ae9-3031dc8b3e6f"
      },
      "source": [
        "# Your Code Here\n",
        "\n",
        "#A lot of models have specific parameters, its a coefficient or a weight that I will multiply values by to calculate my final prediction\n",
        "\n",
        "#Scalaing/standardizing the data\n",
        "scalar = StandardScaler()\n",
        "z = scalar.fit_transform(df.values)\n",
        "\n",
        "# PCA but only retaining the first two principal components\n",
        "pca = PCA(2)\n",
        "pca.fit(z)\n",
        "transformed_data = pca.transform(z)\n",
        "\n",
        "kmeans = Kmeans(2)\n",
        "kmeans.fit(transformed_data)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-86fd721feddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# PCA but only retaining the first two principal components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'M'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nOeWYXkmNep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c9ebebfa-9b5f-4bd5-9145-e0be07deca3e"
      },
      "source": [
        "PCA_dataframe = pd.DataFrame({'a': transformed_data[0:1], 'b': transformed_data[1:2]})\n",
        "PCA_dataframe.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-2658951ffb38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPCA_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mPCA_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transformed_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGyKcVERmMB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "colors = {0:'red', 1:'blue'}\n",
        "grouped = df.groupby('cluster')\n",
        "\n",
        "for key, group in grouped:\n",
        "      group.plot(ax=ax, kind='scatter', x='radius_mean', y='texture_mean', label=key, color=colors[key])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqt3ABKWn9tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get a numeric diagnosis column\n",
        "df['diagnosis'] = df['diagnosis'].astype('category')\n",
        "\n",
        "df['diagnosis'] = df['diagnosis'].cat.codes\n",
        "\n",
        "df.head(25)\n",
        "#1 == malignant\n",
        "#0 == benign\n",
        "\n",
        "for i, row in enumerate(PCA_dataframe.cluster):\n",
        "  if row['cluster'] == df.iloc[i]['diagnosis']:\n",
        "  print(row.cluster)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WwWSI9rp4TQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "7add3db4-406a-4cd3-c7e0-78b74d222893"
      },
      "source": [
        "(PCA_dataframe['cluster'] == df['diagnosis'])[1]/df.shape[0]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-b4814024d03a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mPCA_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'PCA_dataframe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BedOTS0eJ9_K",
        "colab_type": "text"
      },
      "source": [
        "# 2) Perform PCA on your dataset first and *then* use k-means clustering. \n",
        "\n",
        "- You need to standardize your data before PCA.\n",
        "- First try clustering just on PC1 and PC2 so that you can make a scatterplot of your clustering.\n",
        "- Then use use a scree plot to decide how many principal components to include in your clustering, and use however many principal components you need in order to retain 90% of the variation of the original dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1AeAK8PNah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrfbzfBROpP",
        "colab_type": "text"
      },
      "source": [
        "## Check your work: \n",
        "\n",
        "- Compare your PC1, PC2 clustering scatterplot to the clustering scatterplots you made on the raw data\n",
        "- Calculate accuracy scores for both the PC1,PC2 Principal component clustering and the 90% of explained variance clustering.\n",
        "\n",
        "How do your accuracy scores when preprocessing the data with PCA compare to the accuracy when clustering on the raw data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBwVaGOOYsq",
        "colab_type": "text"
      },
      "source": [
        "# Stretch Goals:\n",
        "\n",
        "- Study for the Sprint Challenge\n",
        "- Work on your Data Storytelling Project\n",
        "- Practice your two-minute presentation for your Data Storytelling Project"
      ]
    }
  ]
}